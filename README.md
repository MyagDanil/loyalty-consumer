Loyalty Consumer
Микросервис для обработки транзакций программы лояльности.
Сервис читает события из Kafka, атомарно записывает их в PostgreSQL, обновляет баланс пользователя и кеширует его в Redis для быстрых чтений.

Основные возможности
Консьюмер Kafka (на Go, библиотека sarama) с поддержкой consumer groups и ручным управлением offset’ами.
Атомарная обработка транзакций в PostgreSQL (begin / commit / rollback) с использованием pgx/pgxpool.
Кеширование балансов пользователей в Redis для ускорения чтения и снижения нагрузки на базу.
Валидация входящих событий через go-playground/validator (enterprise-подход).
Логирование в формате JSON (logrus), удобное для интеграции с ELK / Loki.
Контейнеризация через Docker, возможность запуска всех зависимостей через Docker Compose.

Архитектура микросервиса: чёткое разделение слоёв (handler, store, cache, kafka, config).
Учитываются базовые правила безопасности: валидация входных данных, защита от типичных ошибок из OWASP TOP‑10, безопасная работа с конфигурацией через переменные окружения.

Архитектура
Сервис построен по микросервисному подходу и состоит из нескольких слоёв:
cmd/consumer – точка входа, инициализация конфигурации, логгера, подключений к PostgreSQL/Redis/Kafka, запуск консьюмера с graceful shutdown.
internal/handler – бизнес-логика обработки сообщений:
парсинг и валидация JSON-сообщений в структуру Transaction;

открытие транзакции в БД;
вставка записи транзакции и обновление баланса;
commit или rollback;

асинхронное обновление кеша в Redis.
internal/models – DTO/модели домена (например, Transaction) с валидацией через validator и JSON-тегами.
internal/store – слой доступа к данным PostgreSQL (insert/update/select, управление транзакциями).
internal/cache – обёртка над Redis для работы с кешем балансов.
internal/kafka – обёртка над Kafka Consumer Group (sarama), делегирующая обработку сообщений в handler.
internal/config – загрузка конфигурации из переменных окружения и настройка логгера.

Такой подход упрощает тестирование, сопровождение и масштабирование сервиса.

Технологии
Язык: Go (Golang)
Сообщения: Kafka (consumer group, offset management)
Хранение данных: PostgreSQL
Кеш: Redis
Контейнеризация: Docker / Docker Compose
Логирование: logrus (JSON-формат)
Валидация: go-playground/validator
Контроль версий: Git

Запуск локально
Требования
Go (берите актуальную версию, например 1.22+)

Docker и Docker Compose

Запущенные экземпляры Kafka, PostgreSQL и Redis (можно через docker-compose.yml из репозитория)

Шаги

# Клонируем репозиторий
git clone https://github.com/youruser/loyalty-consumer.git
cd loyalty-consumer

# Поднимаем инфраструктуру (Postgres, Redis, Kafka)
docker compose up -d

# Экспортируем базовые переменные окружения
export POSTGRES_DSN="postgres://user:pass@localhost:5432/loyalty?sslmode=disable"
export REDIS_ADDR="localhost:6379"
export KAFKA_BROKERS="localhost:9092"
export KAFKA_GROUP_ID="loyalty-consumer-group"
export KAFKA_TOPIC="loyalty-transactions"
export LOG_LEVEL="info"

# Запускаем сервис
go run ./cmd/consumer
Обработка сообщений
Ожидается, что в Kafka-топике loyalty-transactions лежат сообщения формата JSON:

json
{
  "id": "uuid-транзакции",
  "user_id": "uuid-пользователя",
  "amount": 100,
  "type": "purchase",
  "created_at": "2025-12-04T10:00:00Z"
}
Пайплайн обработки:
Consumer читает сообщение из Kafka.
Handler десериализует JSON в models.Transaction и валидирует данные.
Открывается транзакция в PostgreSQL:
создаётся запись о транзакции;
обновляется баланс пользователя.
Выполняется COMMIT или ROLLBACK при ошибке.
В горутине читается актуальный баланс из БД и записывается в Redis как кеш.
Ошибки Redis не блокируют основную обработку: БД является источником истины, кеш – ускорение.

Безопасность
Валидация всех входящих данных (в том числе типов и диапазонов значений), что помогает избежать части проблем из OWASP TOP‑10 (некорректные данные, неожиданные форматы и т.д.).
Чувствительные данные (строки подключения, креды) хранятся только в переменных окружения, а не в коде.
Логи не содержат секретов, только техническую и бизнес-информацию (ID транзакций, userID, статусы операций).
В REST‑ и других внешних сервисах (если подключаются) может использоваться JWT для авторизации запросов.

Тестирование
Unit‑тесты для:
models.Transaction.Validate();
методов store (insert/update/select) с моками;
cache-слоя.

Интеграционные тесты:
полный сценарий обработки сообщения из Kafka с проверкой записи в БД и состояния кеша в Redis (через локальный Docker Compose).
Возможное развитие

Добавление REST API для получения баланса и истории транзакций.
Метрики Prometheus (кол-во обработанных сообщений, ошибка/успех, latency).
Расширение схемы транзакций (типы операций, дополнительные атрибуты).
Поддержка нескольких топиков и маршрутизация событий по типам.
